# 強化学習の一般論

## マルコフ決定過程(Markov Decision Process: MDP)

MDPは、以下の特徴を持つ。

マルコフ性: 

状態遷移がマルコフ過程に従い、現在の状態だけで将来の状態が確率的に決まる性質を持つ。過去の履歴に依存しないため、状態の遷移が単純化される。

決定性: 

意思決定者がある状態において、可能な行動を選択することによって、次の状態を決定する。意思決定者は、将来の報酬を最大化するために最適な行動を選択する。

確率性: 

状態遷移や報酬は確率的に決まる。つまり、同じ行動を選択しても、異なる状態に遷移し、異なる報酬を得ることがある。

MDPの構成要素は以下の４つである。

- 状態

- 行動

- 状態遷移の確率

- 即時報酬

MDPは強化学習の枠組みそのものであり、モデルベース強化学習はその枠組みを使用して環境モデルを構築し、モデルフリー強化学習はモデルを持たずに直接学習を行う。


## 動的計画法 (Dynamic Programming, DP）


環境の完全なモデルがマルコフ決定過程として与えられている場合にのみ適用できる方法である。


# このリポジトリのコード

## maze.ipynb
Reinforcement learning code for mazes
